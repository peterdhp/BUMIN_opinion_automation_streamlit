import streamlit as st
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_openai import ChatOpenAI
from streamlit_feedback import streamlit_feedback
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain.output_parsers.openai_tools import JsonOutputKeyToolsParser
from typing import List
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser, CommaSeparatedListOutputParser
from langchain_core.tracers.context import collect_runs
from langchain_core.runnables import (
    RunnableLambda,
    RunnableParallel,
    RunnablePassthrough,
    RunnableAssign
)

from menu_streamlit import menu_with_redirect
from operator import itemgetter
import os
from langchain_community.vectorstores import FAISS
import cohere
from langsmith import traceable
from langsmith import Client

os.environ["LANGCHAIN_API_KEY"] = st.secrets['LANGCHAIN_API_KEY']
os.environ["LANGCHAIN_TRACING_V2"] = st.secrets['LANGCHAIN_TRACING_V2']
os.environ["LANGCHAIN_ENDPOINT"] = st.secrets['LANGCHAIN_ENDPOINT']
os.environ['LANGCHAIN_PROJECT'] = st.secrets['LANGCHAIN_PROJECT']


menu_with_redirect()

client1 = Client()
client2 = Client()


def opinion_generator_new(model):
    opinion_prompt = ChatPromptTemplate.from_messages([
        ("system", """You are a doctor at a health screening center. Explain the test results to the patients. Give brief general information about the diagnosis and a recommendation for the patient.
here is an example. 
input : non-specific T wave abnormalitiy
output : ì „ë„ ê²€ì‚¬ì—ì„œ ë¹„íŠ¹ì´ì  T íŒ¡ ì´ìƒ ì†Œê²¬ì´ ê´€ì°°ë©ë‹ˆë‹¤. í—ˆí˜ˆì„± ì‹¬ì§ˆí™˜ ë“±ì—ì„œ ê´€ì°°ë  ìˆ˜ ìˆëŠ” ì†Œê²¬ì´ë‚˜ ì •ìƒì¸ì—ì„œë„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í‰í†µ ë“±ì˜ ì¦ìƒì´ ìˆëŠ” ê²½ìš° ìˆœí™˜ê¸°ë‚´ê³¼ ì§„ë£Œë¥¼ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤."""),
        ("user", """{diagnosis}

ì‹¬""")
    ])

    llm = ChatOpenAI(model_name=model, temperature=0)
    output_parser = StrOutputParser()

    opinion_chain = opinion_prompt | llm | output_parser

    return opinion_chain

def multi_opinion_summary(model):
    opinion_prompt = ChatPromptTemplate.from_messages([
        ("system", """í™˜ìí•œí…Œ ì„¤ëª…í•˜ëŠ” ë‚´ìš©ë“¤ì´ ì—¬ëŸ¬ê°œ ìˆì„ ë•Œ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í•©ì³ì¤˜. ì²« ë¬¸ì¥ì€ 'ã…‡ã…‡ã…‡ ê²€ì‚¬ì—ì„œ ã…‡ã…‡ã…‡,ã…‡ã…‡ã…‡ ë° ã…‡ã…‡ã…‡ì´ ê´€ì°°ë©ë‹ˆë‹¤.'ìœ¼ë¡œ ì‹œì‘í•´ì„œ ì„¤ëª…ì„ ë§ë¶™ì´ê³  ì¶”ì ê´€ì°°, ì–´ë–¤ ê³¼ë¥¼ ê°€ë¼ëŠ” ë‚´ìš©ì„ ë§ˆì§€ë§‰ì— ì ì–´ì¤˜. ë˜ë„ë¡ì´ë©´ ìƒˆë¡œìš´ ë‚´ìš©ì„ ë§Œë“¤ì–´ë‚´ì§„ ë§ì•„ì¤˜."""),
        ("user", """{multi_results}

ì‹¬""")
    ])

    llm = ChatOpenAI(model_name=model, temperature=0)
    output_parser = StrOutputParser()

    opinion_chain = opinion_prompt | llm | output_parser

    return opinion_chain

if "diagnosis" not in st.session_state:
    st.session_state.diagnosis = ''
if "multi_opinion" not in st.session_state:
    st.session_state.multi_opinion = ''
if "opinion_new" not in st.session_state:
    st.session_state.opinion_new = ''
if "opinion_summary" not in st.session_state:
    st.session_state.opinion_summary = ''

if "doc_list" not in st.session_state:
    st.session_state.doc_list = ''

st.title('ìƒˆë¡œìš´ ì†Œê²¬ ìë™ ì™„ì„± ë° ì—¬ëŸ¬ ì†Œê²¬ í•©ì¹˜ê¸°')
feedback_option = "thumbs"
col1, col2 = st.columns(2)
with col1 :
    with st.form('my_form'):
        diagnosis_new = st.text_input('Enter text:', placeholder='ì§„ë‹¨ëª… ì…ë ¥')
        submitted = st.form_submit_button('Submit')
        if not st.session_state.openai_api_key.startswith('sk-'):
            st.warning('Please enter your OpenAI API key!', icon='âš ')
        if submitted and st.session_state.openai_api_key.startswith('sk-'):
            chain = opinion_generator_new(model="gpt-4o")
            with collect_runs() as cb:
                response = chain.invoke(diagnosis_new)
                st.session_state.run_id = cb.traced_runs[0].id
            st.session_state.opinion_new = response # Store the opinion in the session state
    if not st.session_state.opinion_new == '' :
        st.info('*'+st.session_state.opinion_new)
        
    
    if st.session_state.get("run_id"):
        run_id = st.session_state.run_id# Debug print for Run ID
        feedback_1 = streamlit_feedback(
            feedback_type=feedback_option,
            optional_text_label="ì½”ë©˜íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.",
            key=f"feedback_{run_id}",
        )

        # Define score mappings for both "thumbs" and "faces" feedback systems
        score_mappings = {
            "thumbs": {"ğŸ‘": 1, "ğŸ‘": 0},
            "faces": {"ğŸ˜€": 1, "ğŸ™‚": 0.75, "ğŸ˜": 0.5, "ğŸ™": 0.25, "ğŸ˜": 0},
        }

        # Get the score mapping based on the selected feedback option
        scores = score_mappings[feedback_option]

        if feedback_1:
            # Get the score from the selected feedback option's score mapping
            score = scores.get(feedback_1["score"])

            if score is not None:
                # Formulate feedback type string incorporating the feedback option and score value
                feedback_type_str = f"{feedback_option} {feedback_1['score']}"

                # Record the feedback with the formulated feedback type string and optional comment
                feedback_record = client1.create_feedback(
                    run_id,
                    feedback_type_str,
                    score=score,
                    comment=feedback_1.get("text"),
                )
                st.session_state.feedback = {
                    "feedback_id": str(feedback_record.id),
                    "score": score,
                }
            else:
                st.warning("Invalid feedback score.")
            
            
            
with col2 :
    

    with st.form('my_form_2'):
        multi_opinion = st.text_area('Enter text:', placeholder='ì—¬ëŸ¬ ì†Œê²¬ ì…ë ¥', height=400)
        submitted = st.form_submit_button('Submit')
        if not st.session_state.openai_api_key.startswith('sk-'):
            st.warning('Please enter your OpenAI API key!', icon='âš ')
        if submitted and st.session_state.openai_api_key.startswith('sk-'):
            chain = multi_opinion_summary(model="gpt-4o")
            with collect_runs() as cb:
                response = chain.invoke(multi_opinion)
                st.session_state.run_id = cb.traced_runs[0].id
            opinion = response
            st.session_state.opinion_summary = opinion # Store the opinion in the session state
    if not st.session_state.opinion_summary == '' :
        st.info('*'+st.session_state.opinion_summary)
        
    
    if st.session_state.get("run_id"):
        run_id = st.session_state.run_id# Debug print for Run ID
        feedback_2 = streamlit_feedback(
            feedback_type=feedback_option,
            optional_text_label="ì½”ë©˜íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.",
            key=f"feedback_{run_id}",
        )

        # Define score mappings for both "thumbs" and "faces" feedback systems
        score_mappings = {
            "thumbs": {"ğŸ‘": 1, "ğŸ‘": 0},
            "faces": {"ğŸ˜€": 1, "ğŸ™‚": 0.75, "ğŸ˜": 0.5, "ğŸ™": 0.25, "ğŸ˜": 0},
        }

        # Get the score mapping based on the selected feedback option
        scores = score_mappings[feedback_option]

        if feedback_2:
            # Get the score from the selected feedback option's score mapping
            score = scores.get(feedback_2["score"])

            if score is not None:
                # Formulate feedback type string incorporating the feedback option and score value
                feedback_type_str = f"{feedback_option} {feedback_2['score']}"

                # Record the feedback with the formulated feedback type string and optional comment
                feedback_record = client2.create_feedback(
                    run_id,
                    feedback_type_str,
                    score=score,
                    comment=feedback_2.get("text"),
                )
                st.session_state.feedback = {
                    "feedback_id": str(feedback_record.id),
                    "score": score,
                }
            else:
                st.warning("Invalid feedback score.")
            
        